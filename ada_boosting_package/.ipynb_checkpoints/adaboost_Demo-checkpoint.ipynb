{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning2 : AdaBoost Part I "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fill the analysis table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=np.array([[0,-1,-1],[1,0,1],[-1,0,1],[0,1,-1]])\n",
    "df_analysis=pd.DataFrame(columns=['m','w1','w2','w3','w4',\n",
    "                                  'err','alpha',\n",
    "                                  'Gm_x1','Gm_x2','Gm_x3','Gm_x4'])\n",
    "df_analysis.ix[:,'m']=range(1, 5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "x=data[:,0:2]\n",
    "y=data[:,2]\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def base_classifier(w):\n",
    "    # given sample_weight, use stump (max_depth=1) to predict \n",
    "    # return prediction\n",
    "    Gm1=tree.DecisionTreeClassifier(max_depth=1)\n",
    "    Gm1.fit(x, y,sample_weight=w)\n",
    "    return Gm1.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conversion(x_array):  # x_array is an array of T or F\n",
    "    return np.array([1 if x==1 else 0 for x in x_array ])\n",
    "\n",
    "def cal_weights(h, y, w,i):   \n",
    "    err = np.sum(w*(h!=y))/(np.sum(w))\n",
    "    try:\n",
    "        alpha=math.log((1-err)/err)\n",
    "    except: alpha=0.0000000000001\n",
    "    result=conversion(h!=y)\n",
    "    w_new=w*np.exp(alpha*result)\n",
    "    df_analysis.ix[i,['w1','w2','w3','w4']]= w\n",
    "    df_analysis.ix[i,'err']=err\n",
    "    df_analysis.ix[i,'alpha']=alpha\n",
    "    df_analysis.ix[i,['Gm_x1','Gm_x2','Gm_x3','Gm_x4']]=h\n",
    "    print df_analysis\n",
    "    return w_new, err, alpha, h, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   m    w1    w2    w3    w4   err    alpha Gm_x1 Gm_x2 Gm_x3 Gm_x4\n",
      "0  1  0.25  0.25  0.25  0.25  0.25  1.09861    -1     1     1     1\n",
      "1  2   NaN   NaN   NaN   NaN   NaN      NaN   NaN   NaN   NaN   NaN\n",
      "2  3   NaN   NaN   NaN   NaN   NaN      NaN   NaN   NaN   NaN   NaN\n",
      "3  4   NaN   NaN   NaN   NaN   NaN      NaN   NaN   NaN   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "w0=np.ones(4)/4\n",
    "h0=base_classifier(w0)\n",
    "w1,err1,alpha1,h1, result=cal_weights(h0, y, w0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   m    w1    w2    w3    w4       err    alpha Gm_x1 Gm_x2 Gm_x3 Gm_x4\n",
      "0  1  0.25  0.25  0.25  0.25      0.25  1.09861    -1     1     1     1\n",
      "1  2  0.25  0.25  0.25  0.75  0.166667  1.60944     1     1     1    -1\n",
      "2  3   NaN   NaN   NaN   NaN       NaN      NaN   NaN   NaN   NaN   NaN\n",
      "3  4   NaN   NaN   NaN   NaN       NaN      NaN   NaN   NaN   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "h1=base_classifier(w1)\n",
    "w2,err2,alpha2,h2, result=cal_weights(h1, y, w1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   m    w1    w2    w3    w4       err    alpha Gm_x1 Gm_x2 Gm_x3 Gm_x4\n",
      "0  1  0.25  0.25  0.25  0.25      0.25  1.09861    -1     1     1     1\n",
      "1  2  0.25  0.25  0.25  0.75  0.166667  1.60944     1     1     1    -1\n",
      "2  3  1.25  0.25  0.25  0.75       0.1  2.19722    -1    -1     1    -1\n",
      "3  4   NaN   NaN   NaN   NaN       NaN      NaN   NaN   NaN   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "h2=base_classifier(w2)\n",
    "w3,err3,alpha3,h3, result=cal_weights(h2, y, w2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   m    w1    w2    w3    w4        err    alpha Gm_x1 Gm_x2 Gm_x3 Gm_x4\n",
      "0  1  0.25  0.25  0.25  0.25       0.25  1.09861    -1     1     1     1\n",
      "1  2  0.25  0.25  0.25  0.75   0.166667  1.60944     1     1     1    -1\n",
      "2  3  1.25  0.25  0.25  0.75        0.1  2.19722    -1    -1     1    -1\n",
      "3  4  1.25  2.25  0.25  0.75  0.0555556  2.83321    -1     1    -1    -1\n"
     ]
    }
   ],
   "source": [
    "h3=base_classifier(w3)\n",
    "w4,err4,alpha4,h4, result=cal_weights(h3, y, w3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training Error of AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.09861228867\n",
      "[ 1.09861229  1.09861229  1.09861229 -1.09861229]\n",
      "[-4.5196123   3.34403897  2.07206143 -5.54126355]\n"
     ]
    }
   ],
   "source": [
    "print alpha1\n",
    "print h1*alpha1\n",
    "G=h0*alpha1+h1*alpha2 + h2*alpha3 + h3*alpha4 \n",
    "print G\n",
    "y_hat=[1 if g > 0 else -1 for g in G]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "print \"error rate:\", 1-np.mean(y==y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Is above dataset linearly seperable? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above dataset is not linearly sepearable. As we can not draw a line, e.g. set up a threshold so that we can seperate the classes of 0 and 1. AdaBoost does better than a decision stump as AdaBoost uses not only multiple trees to aggregate the result, but also apply higher weights on misclassified data points. As a result, data points which are misclassified gets more attention in the 2nd and 3rd base classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
